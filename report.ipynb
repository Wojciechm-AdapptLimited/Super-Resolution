{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d17a47d-97d7-425b-b360-ae77e5af19c4",
   "metadata": {},
   "source": [
    "# Computer Vision Project #3 - Super Resolution Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b6fc6-fcc3-44ca-82a5-1f7baf57b697",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Table of contents\n",
    "1. [The Dataset](#dataset)\n",
    "2. [The Problem](#problem)\n",
    "3. [Used Architectures](#architecture)\n",
    "4. [Runtime Enviroment](#env)\n",
    "5. [Model analysis](#model)\n",
    "6. [Training](#training)\n",
    "7. [Points Table](#point-table)\n",
    "8. [Bibliography](#bib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54dbf1-7267-43c7-976a-010b33cf5d9e",
   "metadata": {},
   "source": [
    "## Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34c49e-5614-4c9f-891b-4c65e23853f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "from src.utils import imshow,scaled_imshow,seed_everything,plot_model,plot_history\n",
    "from src.blocks.layers import EncoderBlock,DecoderBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf379161-7204-4284-805c-2c02d1d3a1c1",
   "metadata": {},
   "source": [
    "## The Dataset <a class=\"anchor\" id=\"dataset\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead410e-5096-4019-9a91-0136467b7125",
   "metadata": {},
   "source": [
    "### Main dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae13ee8d-b3c7-41a3-8804-965ea5f7636c",
   "metadata": {},
   "source": [
    "The dataset was uploaded to kaggle [here](https://www.kaggle.com/datasets/saputrahas/dataset-image-super-resolution), by user *saputra has*. The dataset created is intended for super-resolution, it consists of over 5000 images. Their sizes are all the same, equalling 1024 x 720."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ee911-8597-433a-bce1-00d4d354b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (400,400)\n",
    "#IMG_SHAPE = (64,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401545d9-0a9b-4134-84e7-f9b7f66a26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        #rotation_range=45,\n",
    "        horizontal_flip = True\n",
    "    )\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"./data/finished/train/dataraw/\",\n",
    "    target_size=IMG_SHAPE,\n",
    "    batch_size=32,\n",
    "    class_mode='input',\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    \"./data/finished/valid/dataraw/\",\n",
    "    target_size=IMG_SHAPE,\n",
    "    batch_size=32,\n",
    "    class_mode='input',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b92d1-a9f9-4a74-a9bc-c5ea27d64725",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(train_generator)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7486a65-9183-4abb-9166-bf362bba5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mosaic(batch,dsize=IMG_SHAPE):\n",
    "    img_shape = dsize + (3,)\n",
    "    mosaic = np.zeros((img_shape[0] * 3, img_shape[1] * 3, img_shape[2]))\n",
    "    # Fill in the mosaic with images\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            index = i * 3 + j\n",
    "            mosaic[i * img_shape[0]:(i + 1) * img_shape[0], j * img_shape[1]:(j + 1) * img_shape[1], :] = batch[index]\n",
    "    scaled_imshow(cv.cvtColor((mosaic*255).astype(np.uint8),cv.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee59aa-f308-4e67-87a5-4208879299b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mosaic(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee798e-8e4f-4564-aed7-3c07a70c454f",
   "metadata": {},
   "source": [
    "The images show people, nature, places, objects, etc. Generally a wide variety of things, however people are a substantial part of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cca340-5cdc-44e0-b9e5-191b79bfb531",
   "metadata": {},
   "source": [
    "### Additional dataset\n",
    "\n",
    "Another dataset was created for the purpose of this project. The dataset contains almost no people in comparison to the main dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58793f-c4ae-47a9-b034-ba7178b0f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "custom_data = custom.flow_from_directory(\n",
    "    \"./data/custom/\",\n",
    "    target_size=IMG_SHAPE,\n",
    "    batch_size=32,\n",
    "    class_mode='input',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6045361-02f3-494a-99ef-fc9104cf93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mosaic(next(custom_data)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec4fe6-2fdd-4369-bde3-17ce14a1e486",
   "metadata": {},
   "source": [
    "## The Problem <a class=\"anchor\" id=\"problem\"/>\n",
    "\n",
    "Super-resolution refers to the task of enhancing the resolution or level of detail in an image, typically by increasing its pixel count. The goal is to generate a high-resolution (HR) image from a low-resolution (LR) or degraded version of the same image. This problem is particularly important in computer vision and image processing, where obtaining high-quality images is crucial for various applications.\n",
    "\n",
    "In this case the model will increase the resolution two times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0f2bc-0aed-48e9-96ba-5422bc9c354e",
   "metadata": {},
   "source": [
    "## Used Architectures <a class=\"anchor\" id=\"architecture\"/>\n",
    "description of used architectures with diagram showing the layers; For large models containing blocks, the blocks and the connections between them can be shown separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469b825-1e61-4a58-82e4-b2ce3633e833",
   "metadata": {},
   "source": [
    "Basic autoencoder consists of an encoder and a decoder. Encoder consists of several Convolution layers with increasing filters, but they decrease the image in size, using Pooling or strides. The decoder on the other hand decreases the number of channels back to 3, but increases the image back in size.\n",
    "The encoder and decoder meet in the middle in a bottleneck, which describes the images in a latent space. Using a lower amount of flat variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dab7d2-9a7b-47b7-8590-4abb25a4c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (400,400)\n",
    "INPUT_SHAPE = (200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c1e98-0568-46cc-add1-83e59d32bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.InputLayer(IMG_SHAPE+(3,)))\n",
    "model.add(layers.Resizing(*INPUT_SHAPE))\n",
    "model.add(EncoderBlock(8))\n",
    "model.add(EncoderBlock(16))\n",
    "model.add(EncoderBlock(32))\n",
    "# model.add(layers.GlobalAveragePooling2D())\n",
    "# model.add(layers.Dense(\n",
    "# model.add(layers.Reshape(target_shape=(45, 64, 128)))\n",
    "model.add(DecoderBlock(32))\n",
    "model.add(DecoderBlock(16))\n",
    "model.add(DecoderBlock(8))\n",
    "model.add(DecoderBlock(8))\n",
    "model.add(layers.Conv2D(8,kernel_size=(3, 3),strides=(1, 1), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Conv2D(3,kernel_size=(3, 3),strides=(1, 1), padding='same'))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.build()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e02d58a-1628-4c67-9152-31914b017f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98361bb7-864b-4063-a04d-8b91afca82c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865e82b-f48c-4155-bba5-35f73a7f8053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a878219e-5cb7-4b10-b1b8-4647994ea476",
   "metadata": {},
   "source": [
    "## Runtime Enviroment <a class=\"anchor\" id=\"env\"/>\n",
    "- maybe run in docker\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53df91-d299-412b-a8b6-749f9a11fd23",
   "metadata": {},
   "source": [
    "## Model analysis <a class=\"anchor\" id=\"model\"/>\n",
    "- size in memory, number of parameters,  \n",
    "- comparison of models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963de7a6-0214-474e-9054-10046f4531f7",
   "metadata": {},
   "source": [
    "## Training <a class=\"anchor\" id=\"training\"/>\n",
    "- training and inference time,\n",
    "- description of the training and the required commands to run it\n",
    "- description of used metrics, loss, and evaluation\n",
    "- plots: training and validation loss, metrics\n",
    "- used hyperparameters along with an explanation of each why such value was chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece622a-439a-49c7-9928-86fd9d6d5542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,batch_size=4,epochs=5,validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb2941-1fd0-49ff-8fcd-442e531f8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57213af-59b3-4333-b476-7e9c9fdae176",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(custom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bfe1b-5a7d-4990-ac50-2ede664028f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(custom_data)[0]\n",
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5fe36-e891-4534-9059-3c2e410f5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mosaic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa92f1-d2e8-411c-a885-eb049fac4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mosaic(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65207f87-e5f9-40b1-914a-6e70b737e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x[0]*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d057262-59c0-47da-9d40-07564a25c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(y_pred[0]*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be32fe5-671f-4df9-adf5-3b270daa32ca",
   "metadata": {},
   "source": [
    "## Points Table <a class=\"anchor\" id=\"point-table\"/>\n",
    "\n",
    "| Type    | Item                 | Points |\n",
    "|---------|----------------------|--------|\n",
    "| Problem | Super Resolution     | 3      |\n",
    "| Model   | Autoencoder          | 1      |\n",
    "| Dataset | Our own dataset      | 1      |\n",
    "| Sum     | sum of points        | 5      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f213fb44-be17-41e1-ae64-90e4c2aa84a2",
   "metadata": {},
   "source": [
    "## Bibliography <a class=\"anchor\" id=\"bib\"/>\n",
    "preparation of a bibliography - the bibliography should contain references to the data set (preferably the article in which the collection was presented) and all scientific works and studies, including websites with tips on the solution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
